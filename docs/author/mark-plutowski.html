<!DOCTYPE html>
<html lang="en">
<head>
        <title>Plutosoft delimited - Mark Plutowski</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="https://pluteski.github.io/speech-to-text/theme/css/main.css" type="text/css" />
        <link href="https://pluteski.github.io/speech-to-text/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Plutosoft delimited ATOM Feed" />

        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="https://pluteski.github.io/speech-to-text/css/ie.css"/>
                <script src="https://pluteski.github.io/speech-to-text/js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="https://pluteski.github.io/speech-to-text/css/ie6.css"/><![endif]-->

</head>

<body>
<a href="https://github.com/pluteski">
<img style="position: absolute; top: 0; right: 0; border: 0;" src="http://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub" />
</a>
        
        

	<header>
		<h1><a href="https://pluteski.github.io/speech-to-text" id="site-title">Plutosoft delimited </a> : <a href="https://pluteski.github.io/speech-to-text/review-of-the-book-life-30-by-max-tegmark.html" id="page-title">Review of the book “Life 3.0" by Max Tegmark.</a></h1>
<time datetime="2018-05-20T00:00:00-07:00">Sun 20 May 2018</time>	</header>

	<article>
		<h1>Book Review</h1>
<p><strong>"Life 3.0 : Being Human in the Age of Artificial Intelligence”</strong> by Max Tegmark.</p>
<h1>Tl;dr</h1>
<p>A hot mess early in but is worth it in the end.</p>
<h1>Summary</h1>
<p>Perhaps the most important book I’ve read on the topic. That said, it drags badly in the middle. The first chapter excels. Subsequent early chapters may disappoint well read aficionados. Hang in there until mid-way.</p>
<h1>Book Edition</h1>
<p>This is a review of the Audio Edition of Life 3.0 by Max Tegmark.  The audio edition I read was separated into 45 segments, or “chapters”, which differ from the chapters of the text version.</p>
<h1>Intro</h1>
<p>The first chapter is terrific. The opening chapter was fiction, laying out a speculative hard science vision that seemed so plausible as to seem frighteningly inevitable. This is the stuff of inspired script-writing that could be the premise for an excellent motion picture, with enough to work with to launch a serial.</p>
<p>After that smoking intro, a hot mess ensues
This book reminded me of the Beatles song “For You Blue”. That song starts out with an inspired intro by George Harrison, before settling into a fairly basic 12 bar blues that is over self congratulatory. A review by music critic Walter Everett summed it up: the intro promises more than the song delivers.  Why does this book remind me of that song? Because the opening chapter was terrific, only to fall into a hot mess the next third of the way.</p>
<p>It would be as if Slash opened “Sweet Child o Mine” with that famous riff only to never launch into his face-melting guitar solo midway into the song.</p>
<p>I read about a hundred other reviews of the book to see if it was worthwhile to continue. I agreed with none of the five star reviews, and I agreed with all of the one star and two star reviews. Although I would put myself into the camp that agrees with the author’s position, after that page-turner of a first chapter I found the following chapters to be very disappointing. Too much name dropping, too much subjective opinion and appeal to authority.  Seemingly glossing over or entirely dismissive of contrary views. There is a notion of “steelmanning”, where the proponent explains the best form of the opponent's argument, and then argues with this. I wished the author had adopted that approach. It seemed to be shaping up as a decent read for the person who knows little about the topic, but not for someone who has devoured much of it and wants clarity and sound opinion and insight into what the future really may hold, from someone who claims to have the answer.</p>
<p>For example in chapter 17, I found myself in total agreement with the author’s positions, but there were explanations having what I would generously consider to be inconsistencies, at best loosely stated and at worst under informed. It was as if these sections had been delegated to a ghost writer and not reviewed closely enough by the author. If I had been asked to give my recommendation at this point, I would have suggested: better to read some top notch science fiction futurism than this ivy tower academic analysis which is far too narrow despite the occasional insight and moments of inspired foresight. It was, in my admittedly subject opinion, all over the map with moments of brilliance while falling well short of its titular claims.</p>
<p>But I pressed on.</p>
<h1>It starts growing on me</h1>
<p>Around chapter 19 (of 45 in the audio version), the author starts to analyze attacks based on fictional scenario posed in chapter 1.  The author delves into a simulation based test and development approach to verification and validation. I found this alone to be worth the price of admission. Much of this still has little with AI per se unless your position is that AI = computer automation, with which I actually agree despite my criticism.</p>
<p>I started to reconsider, now of the mind that most of those one and two star reviews were too harsh and misleading, possibly written by readers who didn’t stick with it long enough.</p>
<p>Around chapter 30 the author dives into cosmology, his specialty. It blossoms into a much more interesting brand of futurism. There were still times where I wondered if the material had been written by a ghost writer who knew much less than the author.  As a specific example of this, describing Dyson Spheres as if they would really be spheres, when by now anybody with a college level physics education or even a moderate familiarity with hard science fiction physics knows that Dyson Spheres are unstable, and these would really be Dyson swarms.  This is something that the author would clearly know, which became clearly apparent based on the knowledge conveyed later on.</p>
<h1>Mind Blown</h1>
<p>Chapter 34 delves into the subject of Goals and Causality.</p>
<p>We have been taught to think of entropy as the one true law of nature that trumps all others.  But if not for gravity, entropy is boring.  Gravity makes things interesting --- it creates hot spots, from one of which sprang life as we know it.</p>
<p>We are introduced to the notion of dissipation as organization principle, whereby :</p>
<div class="highlight"><pre><span></span>“groups of particles strive to organize themselves so as to extract energy from their environment as efficiently as possible (“dissipation” means causing entropy to increase, typically by turning useful energy into heat, often while doing useful work in the process)”
</pre></div>


<p>My eyes and my mind start to open.</p>
<p>Then, we move on to “dissipation by replication”:</p>
<div class="highlight"><pre><span></span><span class="err">“</span><span class="n">Whereas</span> <span class="n">earlier</span><span class="p">,</span> <span class="n">the</span> <span class="n">particles</span> <span class="n">seemed</span> <span class="n">as</span> <span class="n">though</span> <span class="n">they</span> <span class="n">were</span> <span class="n">trying</span> <span class="n">to</span> <span class="n">increase</span> <span class="n">average</span> <span class="n">messiness</span> <span class="p">[</span><span class="n">life</span> <span class="n">had</span><span class="p">]</span> <span class="n">a</span> <span class="n">different</span> <span class="nl">goal</span><span class="p">:</span> <span class="n">not</span> <span class="n">dissipation</span> <span class="n">but</span> <span class="n">replication</span><span class="p">.</span><span class="err">”</span>

<span class="err">“</span><span class="n">How</span> <span class="n">could</span> <span class="n">the</span> <span class="n">goal</span> <span class="n">change</span> <span class="n">from</span> <span class="n">dissipation</span> <span class="n">to</span> <span class="n">replication</span> <span class="n">when</span> <span class="n">the</span> <span class="n">laws</span> <span class="n">of</span> <span class="n">physics</span> <span class="n">stayed</span> <span class="n">the</span> <span class="n">same</span><span class="o">?</span> <span class="n">The</span> <span class="n">answer</span> <span class="n">is</span> <span class="n">that</span> <span class="n">the</span> <span class="n">fundamental</span> <span class="n">goal</span> <span class="p">(</span><span class="n">dissipation</span><span class="p">)</span> <span class="n">didn</span><span class="err">’</span><span class="n">t</span> <span class="n">change</span><span class="p">,</span> <span class="n">but</span> <span class="n">led</span> <span class="n">to</span> <span class="n">a</span> <span class="n">different</span> <span class="n">instrumental</span> <span class="n">goal</span><span class="p">,</span> <span class="n">that</span> <span class="n">is</span><span class="p">,</span> <span class="n">a</span> <span class="n">subgoal</span> <span class="n">that</span> <span class="n">helped</span> <span class="n">accomplish</span> <span class="n">the</span> <span class="n">fundamental</span> <span class="n">goal</span><span class="p">.</span><span class="err">”</span>

<span class="err">“</span><span class="n">replication</span> <span class="n">aids</span> <span class="n">dissipation</span><span class="p">,</span> <span class="n">because</span> <span class="n">a</span> <span class="n">planet</span> <span class="n">teeming</span> <span class="n">with</span> <span class="n">life</span> <span class="n">is</span> <span class="n">more</span> <span class="n">efficient</span> <span class="n">at</span> <span class="n">dissipating</span> <span class="n">energy</span><span class="p">.</span> <span class="n">So</span> <span class="k">in</span> <span class="n">a</span> <span class="n">sense</span><span class="p">,</span> <span class="n">our</span> <span class="n">cosmos</span> <span class="n">invented</span> <span class="n">life</span> <span class="n">to</span> <span class="n">help</span> <span class="n">it</span> <span class="n">approach</span> <span class="n">heat</span> <span class="n">death</span> <span class="n">faster</span><span class="p">.</span><span class="err">”</span>
</pre></div>


<p>This was absolutely mind-boggling for me -- despite my first introduction to machine learning having been via physics, in the way of (Little-)Hopfield Networks, which evolve by minimizing energy as does a physical spin network. That this objective criterion could encompass not only inert matter as well as live matter made me realize that this could be a more fundamental drive for life than Darwinian Evolution.</p>
<p>We are introduced to the notion of subgoals.  Seemingly simple, but at the heart of computer programming.  In 1936 Alan Turing proved that a simple machine could implement arbitrary computations.  This would seem to give us hope that we can override our firmware, just as emotions override our fundamental drive to replicate and ability to plan overrides our need to even more urgent subgoals such as thirst and hunger. If we are capable of that level of reprogramming, then handling rogue AI is just a matter of careful design and test.</p>
<p>Subgoals</p>
<ol>
<li>Replication by ... eating, sleeping,</li>
<li>Feelings : As a computationally efficient shortcut to reasoning.</li>
</ol>
<p>We've evolved useful rules of thumb to guide our decisions : hunger, passion, thirst, pain, compassion.
We no longer have the simple goal of replication.
We can override our base programming and decide not to replicate.
In other words, we've developed subgoals that override the drive to replicate</p>
<p>Feelings evolved beyond being simply an efficient shortcut heuristic.
Feelings evolved into emotions, which have important other uses,
including as a game theoretic negotiating strategy for both cooperation as well as competition.
Humans have evolved sophisticated ways of getting beyond tit-for-tat
such as <a href="http://rspb.royalsocietypublishing.org/content/276/1660/1339">indirect reciprocation</a>,
and aggressive bold play by pretending to be irrational
cf. <a href="http://bigthink.com/think-tank/it-pays-to-be-stubborn-conflict-resolution-steven-pinker-style">Steven Pinker</a></p>
<p>We are an existence proof that a sufficiently ambitious organism can develop subgoals that override the goals of
the micro organisms that make it up.
We can override our genetic programming, using our wetware programming -- lessons learned by thinking.</p>
<h1>Life as Max Tegmark Sees It</h1>
<p>Phases of Goal oriented behavior over the course of the universe :</p>
<ol>
<li>Matter intent on maximizing dissipation</li>
<li>Life maximizing replication</li>
<li>Humans pursuing goals related to feelings they evolved to help them replicate</li>
<li>Machines built to help humans achieve their human goals</li>
</ol>
<p>In Step 3 humans broke free from programming evolved to do Step 2, but we're still not completely free from this programming.</p>
<p>To qualify as AI a machine must be able to learn (unless you adopt the "AI = computer automation" view).
Therefore, we should expect that a sufficiently advanced AI that is able to improve itself, will reprogram itself.</p>
<p>From his Physics perspective, sufficiently evolved AI can be expected to eventually follow goals deeper principles of optimization
to create a future that does not need us.</p>
<p>The ultimate origin of goals lie in the laws of physics, which involve Optimization.
Thermodynamics has the built-in goal of dissipation, to increase entropy.
Life increases dissipation (and therefore entropy of its environment) even faster,
while increasing complexity (and reducing entropy locally).</p>
<h3>Optimization versus Causality.</h3>
<div class="highlight"><pre><span></span>“Causality is taught -- but Optimization scales better.” -- Steven Wolfram, on Machine Learning vs Symbolic AI.
</pre></div>


<p>But what if causality baked into the program can be leapfrogged by the core drive to optimize?
What if that isn’t just a possibility, but a strong probability?  This tied to algorithmic complexity.
The relentless need to optimize inevitably leads to the scenario where :  “a superintelligent AI with a rigorously defined goal will be able to improve its goal attainment by eliminating us”, that is, unless we plan accordingly.</p>
<p>There are many systems that humankind created, which seemed to take on a life of their own, threatening to run away from us, some resulting in existential crisis.  Warcraft and ozone depletion are two examples.  So far, we’ve been able to recover in time and refactor these systems.</p>
<p>“This means that to wisely decide what to do about AI development, we humans need to confront not only traditional computational challenges, but also some of the most obdurate questions in philosophy”</p>
<p>I will not, as many reviewers may, distill these later chapters down -- I leave them as an exercise for the interested reader.  I started out a skeptic of AI alarmism.  Now, I am a believer in AI alarmism being based on rational fears. Not only can this outcome happen, but it is inevitable unless we plan accordingly.</p>
<p>We’ve tackled other wicked difficult problems, such as the tragedy of the commons in its numerous forms, and myriad impossibility theorems that would seem to doom us all. And yet, here we are. Thus far we have always discovered a workaround to impending doom.</p>
<p>This is a wicked difficult problem, but one we can tackle, with the right understanding of its core drivers at its most fundamental level.  After reading this book, I feel like I understand what that is for the first time.</p>
<ol>
<li>Utilitarianism : subject to the Utility Monster</li>
<li>Diversity : Thompson Sampling writ large.</li>
<li>Autonomy : UN, libertarianism, Free Market, property rights.<ul>
<li>eventually leads to an efficient equilibrium economists call Pareto Optimality</li>
<li>but can also lead to banning all predators : all life forms would have a right to live</li>
<li>in the extreme, would ban discriminating against non-human animals</li>
</ul>
</li>
<li>Legacy<ul>
<li>elders have a say in how descendants should behave</li>
<li>but is subject to future generations living by rules that don't account for new developments, or evolving interests.</li>
</ul>
</li>
</ol>
<p>In short: It is difficult to codify ethics.</p>
<p>Rather than be paralyzed by our inability to codify ethics, let's start with Kindergarten Ethics.
For example : Thou Shalt Not Pilot Airplanes Into Obstacles</p>
<p>=&gt;  Any sufficiently ambitious goal can lead to subgoals that cause problems for humans.</p><p>There are <a href="https://pluteski.github.io/speech-to-text/review-of-the-book-life-30-by-max-tegmark.html#disqus_thread">comments</a>.</p>	</article>
		<section id="article-list">
			<h2>All posts</h2>
			<ol>
			</ol>
			</section><!-- #article-list -->
        

 
		<li><a href="https://pluteski.github.io/speech-to-text/the-dirt-on-hashgraph.html" rel="bookmark" title="Permalink to The dirt on Hashgraph">The dirt on Hashgraph</a></li>
			</ol>
			</section><!-- #article-list -->
        

 
		<li><a href="https://pluteski.github.io/speech-to-text/on-bleu-scores-and-transcription-rates.html" rel="bookmark" title="Permalink to on Bleu scores and transcription rates">on Bleu scores and transcription rates</a></li>
			</ol>
			</section><!-- #article-list -->
        

 
		<li><a href="https://pluteski.github.io/speech-to-text/on-batch-processing-audio-speech-to-text.html" rel="bookmark" title="Permalink to on batch processing audio speech to text">on batch processing audio speech to text</a></li>
			</ol>
			</section><!-- #article-list -->

        <footer>
            <nav>
                <ul>
                </ul>
            </nav>
                <p id="theme-credit"><a href="http://mathieu.agopian.info/mnmlist/theme.html">Thème mnmlist</a></p>
        </footer>

<script type="text/javascript">
    var disqus_shortname = 'pluteski-github-io-speech-to-text';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</body>
</html>