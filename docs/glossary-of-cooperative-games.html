<!DOCTYPE html>
<html lang="en">
<head>
        <title>Plutoware delimited : Glossary of Cooperative Games</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="https://pluteski.github.io/speech-to-text/theme/css/main.css" type="text/css" />
        <link href="https://pluteski.github.io/speech-to-text/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Plutoware delimited ATOM Feed" />

        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="https://pluteski.github.io/speech-to-text/css/ie.css"/>
                <script src="https://pluteski.github.io/speech-to-text/js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="https://pluteski.github.io/speech-to-text/css/ie6.css"/><![endif]-->

</head>

<body>
<a href="https://github.com/pluteski">
<img style="position: absolute; top: 0; right: 0; border: 0;" src="http://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub" />
</a>
        
<header>
    <h1><a href="https://pluteski.github.io/speech-to-text" id="site-title">Plutoware delimited </a> :
        <a href="https://pluteski.github.io/speech-to-text/glossary-of-cooperative-games.html" id="page-title">Glossary of Cooperative Games</a></h1>
<time datetime="2018-10-07T00:00:00-07:00">Sun 07 October 2018</time></header>
<article>
    <h1>Glossary of terms</h1>
<p>The following terms are related to cooperative game theory and cooperative economics.  Definitions are drawn from 
<strong>A Cooperative Species : Human Reciprocity and Its Evolution</strong> 
By Samuel Bowles &amp; Herbert Gintis, 2011 (<a href="http://library.uniteddiversity.coop/Cooperatives/A_Cooperative_Species-Human_Reciprocity_and_Its_Evolution.pdf">pdf</a>).  </p>
<p>This document is for educational purposes only. </p>
<h2>Noncooperative games</h2>
<p>Cooperation is possible in non-cooperative games but is achieved only by players playing rational strategies, based on self-interest, only. This type of cooperation is perhaps more accurately deemed "coordination."  In noncooperative games it is not possible to coordinate through agreements or enforcement.  </p>
<h2>Cooperative games</h2>
<p>In cooperative games it is possible to make a binding agreement. Agreement can be tacit or explicit. What makes it possible to bind the agreements is some mechanism (possibly outside the game) that enforces the agreement and makes them have consequence, such as </p>
<ul>
<li>being enforced by a third party, or </li>
<li>a code of conduct that is respected by each participant.</li>
</ul>
<p>Cooperative games can utilize noncooperative mechanisms (that are coordinated purely on the basis of self-interest), and in addition can also use mechanisms that are not allowed in noncooperative games based on agreement. Rules may be encoded in cultural institutions, or agreed upon via social norms that may be understood but not written down anywhere. Conduct may be enforced either by a third party (such as a police force), or by members of the group (such as individuals acting on their own conscience, or by members of the group that take it upon themselves to enforce group norms). </p>
<h2>Evolutionary games</h2>
<p>The key idea in evolutionary game theory is differential replication over many rounds rather than best response over one or more rounds. </p>
<p>Successful strategies in an evolutionary game are those that make more than the average number of replicas in the next period either because </p>
<ul>
<li>they are favored in the process by which people learn new strategies, or </li>
<li>the genotypes expressing the strategies are induced to proliferate by the process of natural selection.</li>
</ul>
<h2>Coordinating device</h2>
<p>Also known as a coordinating signal, this is a mechanism that coordinates the behavior of cooperative agents.  Examples:</p>
<ul>
<li>Traffic signal</li>
<li>Social emotions</li>
<li>Police force</li>
</ul>
<p>A correlating device is something that sends out signals, private or public, to the players of a game, indicating which strategy each should play. </p>
<p>A correlated equilibrium is a situation in which there is a correlating device such that, if all players follow the advice of the correlating device, no player can do better by switching to an alternative strategy.</p>
<p>Correlated equilibrium rather than Nash equilibrium is the appropriate equilibrium concept for cooperative game theory. Recent advances in algorithmic game theory are showing that correlated equilibrium is the better choice for game theory generally, based on computational feasibility. </p>
<h2>Self-interest axiom</h2>
<p>The self-interest axiom says that people seek to maximize their expected payoffs and believe that others do the same</p>
<p>Sometimes this axiom is defended as being self-evident, with the fallback assertion being that natural selection could not have produced any other kind of preferences. </p>
<blockquote>
<blockquote>
<p>“The first principle of economics is that every agent is actuated only by self interest” (1881). -- F. Y. Edgeworth, a founder of neoclassical economics</p>
</blockquote>
</blockquote>
<p>Cooperative economics questions this assertion, claiming that while self-interest is a good explanation of some human behavior, it cannot explain all human behavior.</p>
<h2>Alice, Bob, and Carol</h2>
<p><a href="https://en.wikipedia.org/wiki/Alice_and_Bob">Alice and Bob</a> are fictional characters commonly used as placeholder names in economics and game theory.</p>
<h2>Free riders</h2>
<p>A person free rides if he benefits from the contributions of other group members while himself contributing less or nothing at all. A <strong>shirker</strong> is an otherwise trustworthy group member who temporarily avoids performing their civic duty. Shirking is a milder form of free riding.</p>
<h2>Reciprocity</h2>
<h4>Strong reciprocity</h4>
<p>Strong reciprocity is when people sacrifice their own payoffs in order to cooperate with others, to reward the cooperation of others, and to punish free-riding, even when they cannot expect to gain from acting this way. 
The term “strong” intended to distinguish this set of preferences from entirely amoral and self-regarding reciprocation that would not be undertaken in the absence of some payback. </p>
<h4>Indirect reciprocity</h4>
<p>Indirect reciprocity occurs when Carole is likely to punish Alice when Alice has been unfair to Bob, and is likely to reward Alice when Alice has been nice to Bob. </p>
<h4>Strategic reputation-building</h4>
<p>Strategic reputation-building occurs when Carole behaves cooperatively only when her actions are seen by others, and hence can help build a reputation for social behavior.</p>
<h2>Altruism</h2>
<p>Because the strong reciprocator would increase his game payoffs by not cooperating, the motives for behaving this way are considered to be "altruistic". This does not necessarily mean "kind" -- a group member that is punishing a second individual for violating group norms might use violent means to do so -- the altruism here is for the benefit of the group, not the individual being punished.</p>
<h2>Preferences, Beliefs, and Constraints</h2>
<p>The beliefs, preferences, and constraints model is a key tool in economics and decision theory. According to this approach, what individuals do when restricted to a specific set of feasible actions depends on their <strong>desires</strong> and <strong>goals</strong> on the one hand, and their <strong>beliefs</strong> on the other. </p>
<p><strong>Constraints</strong> represent the limitations placed on the feasible actions an individual may take in a given situation. </p>
<p><strong>Beliefs</strong> are an individual’s representation of the causal structure of the world, including the relationship between the individual’s actions and the probabilities of the various possible resulting outcomes. </p>
<p><strong>Preferences</strong> are the pro or con sentiments that make up the individual’s valuation of the various possible outcomes of taking an action. Preferences may be described as a preference function giving an ordering of the states of the world that may result from one’s actions.</p>
<p>Preferences satisfy two conditions: </p>
<ol>
<li>they are <strong>complete</strong> (any two states can be compared) and </li>
<li>transitive; that is, <strong>consistent</strong>, so that if one prefers A to B and B to C, one then prefers A to C. </li>
</ol>
<p>Preferences are the results of a variety of influences: tastes (food likes and dislikes, for example), habits, emotions (such as shame or anger) and other visceral reactions (such as fear), the manner in which individuals construe situations (or more narrowly, the way they frame decisions), commitments (like promises), internalized norms of ethical behavior, psychological propensities (for aggression, extroversion and the like), and affective relationships with others.</p>
<p>An individual’s behavior can be succinctly and analytically summarizes as maximization of a preference function.</p>
<p>To say that individuals act on their preferences means that knowledge of these preferences provides a concise and accurate account of their actions, given their beliefs and constraints . </p>
<p>A version of the beliefs, preferences, and constraints model, incorporating the behavioral assumptions sometimes summarized as Homo economicus, has become standard not only in economics but throughout the human behavioral sciences. </p>
<p>Self-interest need not be part of the preferences, beliefs, and constraints approach. Preferences could be altruistic or even masochistic.</p>
<h2>Social Preferences and Social Dilemmas</h2>
<p>Social preferences are defined as the concern for the well-being of others and a desire to uphold ethical norms.</p>
<h2>Self-regarding preferences</h2>
<p>Self-regarding preferences are based on states concerning oneself alone. Self-regarding preference can be hard to detect, but can surface in some ways, for example by someone experiencing anxiety in a culturally unfamiliar interaction. </p>
<p><strong>Other-regarding</strong> preferences are based at least in part on states that occur to others, valuing the well-being of other people in the group. An other-regarding player cares about not only his own payoff, but that of other people as well.</p>
<h2>Ethics vs Morals</h2>
<p>Ethics and morals both relate to “right” and “wrong” conduct. Ethics refer to rules provided by an external source, such as workplace rules or religious principles. Morals refer to an individual's own principles regarding right and wrong. </p>
<p><strong>Ethical commitments</strong> may reflect a concern for the states experienced by others, but need not. </p>
<ul>
<li>One can be honest because one seeks to avoid imposing costs on others by deceiving them.  </li>
<li>Honesty could be entirely self-regarding, practiced in order to be the kind of person one wants to be.  </li>
<li>The textbook “economic man” would be described not only as self-regarding, but as amoral as well.</li>
<li><strong>self regarding</strong> is defined a amoral and self-interested. </li>
</ul>
<p><strong>Self-esteem</strong> is dependent in part upon what others think of us. We attempt to favorably impress others as a means of raising our subjective self-esteem.</p>
<p>Having <strong>social preference</strong> means being “unselfish” and “non-self-interested”. </p>
<h4>Examples of games</h4>
<p><strong>dictator game</strong>: Alice gives a certain amount of money to Bob, who has no say in the matter. </p>
<p><strong>third-party punishment game</strong></p>
<p>Games typically have multiple variants that can tease out nuances in behavior. There is a variant on the dictator game that proceeds as follows: </p>
<ol>
<li>Carole, the “third party,” has an endowment of 50 tokens and observes Alice’s transfer. </li>
<li>After this Carole can assign punishment points to Alice. </li>
<li>Each punishment point assigned to Alice costs Carole one token and Alice incurs a penalty of three tokens. </li>
<li>Because punishment is costly, a self-regarding Carole will never punish. </li>
<li>However, if there is a sharing norm, Carole may well punish Alice if she gives too little.</li>
</ol>
<p><strong>trust game</strong> : </p>
<ol>
<li>Alice is awarded a sum of money and given the opportunity to transfer any amount of it to Bob, knowing that the experimenter will triple the amount transferred (if Alice gives x, Bob receives 3x). </li>
<li>Bob then has the opportunity to return some of this augmented sum to Alice. </li>
<li>This ends the game. </li>
</ol>
<p>Alice is sometimes called the “truster” or “investor,” and Bob the “trustee.”</p>
<h4>Social dilemmas</h4>
<p>These are interactions in which the uncoordinated actions of individuals result in an outcome that is Pareto inefficient, meaning that there exists some other feasible outcome such that at least one member could be better off while no member would be worse off. </p>
<p>Examples of social dilemmas modeled by game theorists are </p>
<ul>
<li>the prisoner’s dilemma, </li>
<li>the public goods game, sometimes termed an n-person prisoner’s dilemma, </li>
<li>war of attrition and other arms race interactions, </li>
<li>the tragedy of the commons and the common pool resource game in which contributing to the common project takes the form of forgoing the overexploitation of a jointly utilized resource such as a fishery, water supply, or forest. </li>
</ul>
<p>Social preferences convert a prisoner’s dilemma material payoff structure into what is called an <strong>assurance game</strong> payoff structure — each player will cooperate if assured that the other will cooperate as well, and will not if not.  Mutual cooperation and mutual defection are both Nash equilibria. 
Which of the two Nash equilibria will obtain depends on the players’ beliefs about what the other will do.</p>
<p>The private nature of signals is what makes The Prisoner’s Dilemma a dilemma.</p>
<p>Robert Aumann won the Nobel prize in 2005 (shared with Thomas Schelling) for contributions to game theory. He showed that co-operation is less likely </p>
<ul>
<li>when there are many participants, </li>
<li>when interactions are infrequent, </li>
<li>when the time horizon is short or </li>
<li>when others' actions cannot be clearly observed.</li>
</ul>
<h2>Genes, Culture, Groups, and Institutions</h2>
<p>According to gene-culture coevolution, human preferences and beliefs are the product of a dynamic whereby genes affect cultural evolution and culture affects genetic evolution, the two being tightly intertwined in the evolution of our species</p>
<h1>Primers</h1>
<h2>Agent-based modeling</h2>
<p>This is a tool for analyzing complex dynamical systems as a complement to explicit mathematical analysis where the latter is either impossible or uninformative. </p>
<ul>
<li>In these models, the actors are individual agents who share many characteristics, but differ on key characteristics that affect their relative reproductive success, material payoffs or other results that affect the differential replication of distinct types of individuals. </li>
<li>The agents operate semi-autonomously, but are linked through a network of structured interactions. </li>
<li>The individual characteristics in a complex system evolve through a process of replication, mutation, and finally selection that favors relatively successful individuals. </li>
<li>Such dynamics are recursive, meaning that changes in one period become the basis for changes in future periods, </li>
<li>Such dynamics are non-linear, which implies that forces propagate through the system in an uneven and variably dampened or amplified manner, with the implication that they are generally incapable of being expressed as closed-form analytical solutions to sets of equations.</li>
</ul>
<p>Such modeling (often called “<strong>simulation</strong>”) lies outside the two standard methods of gaining scientific knowledge: <strong>deduction</strong> and <strong>induction</strong>. </p>
<ul>
<li>Deduction means proving theorems, that is, showing that certain mathematical conclusions follow from certain axioms.</li>
<li>Induction means finding lots of evidence and drawing conclusions </li>
</ul>
<p><bold><center>Figure A1: Structure of evolutionary game-based simulation</center></bold>
<center>
<img src="http://github.com/pluteski/speech-to-text/raw/master/blog/content/images/cooperative_species/cooperative_game_params.png" width="400" height="600" />
</center></p>
<p><strong>Agent-based modeling</strong> is like deduction in that it starts with a rigorously specified computer program, but it is like induction in that it treats the operation of the program as a set of data points from which generalizations can be made. </p>
<p>If a complex system has <strong>emergent properties</strong>, these can be ascertained by implementing an agent based model in which these properties are seen and persist over many simulations. </p>
<p>How do we judge the empirical adequacy of an agent-based model? </p>
<ol>
<li>one can ensure that the parameters chosen are empirically plausible for the populations under study. <ul>
<li>Sensitivity analysis: check how much difference variations in the parameters make for the results of the simulation. </li>
<li>On the basis of this sensitivity analysis then spend special attention making sure that the parameters that matter are well estimated. </li>
</ul>
</li>
<li>Exploit the fact that while the processes under investigation are unknown (which is why we are simulating them), that the following hold: <ul>
<li>The simulations generate a large number of by-product statistics on aspects of the relevant populations on which we do have some knowledge. </li>
<li>Thus we can ask whether the results of the simulation conform to known facts about the populations under study. Meaning, they have some predictive appeal -- the hypothesis is that their data will match that of the real system in 2nd and 3rd order effects not just the immediate.</li>
<li>Where the models have generated implausible by-product statistics, diagnose the source of the problem and recalibrate. </li>
</ul>
</li>
</ol>
<p><center><bold>Figure A2: Structure of replication process.</center></bold>
<center>
<img src="http://github.com/pluteski/speech-to-text/raw/master/blog/content/images/cooperative_species/a2_replication_process.png" width="640" height="480" />
</center></p>
<h2>Game Theory</h2>
<p>Game theory is a mathematical tool for the study of strategic interactions where payoffs of individuals depend on their own actions and the actions taken by others. </p>
<h4>On strategy</h4>
<p>A player's <strong>strategy</strong> is any of the options he or she can choose in a setting where the outcome depends not only on their own actions but on the action of others.</p>
<p>A <strong>pure</strong> strategy determines all your moves during the game, and should therefore specify your moves for all possible other players' moves. </p>
<p>A <strong>mixed</strong> strategy is a probability distribution over all possible pure strategies, some of which may get zero weight. </p>
<p>A state is a <strong>Nash equilibrium</strong> if every player’s choice is a best response to the choices of the other players. The choices of all other players are public, known to and understood by every other player. </p>
<p>A <strong>dominant strategy</strong> offers a higher payoff than any other strategy, no matter what the other players do. </p>
<p>A <strong>non-strategic</strong> behavior means that it would be considered non-rational according to neoclassical models based on non-cooperative game theory.</p>
<h4>Repeated games</h4>
<p>A <strong>stage game</strong> of the repeated game is repeated indefinitely, with a positive probability of terminating the process at the end of each period </p>
<p>The most important fact about the repeated game based on stage game G is that it can support cooperative equilibria in situations where G cannot.</p>
<h4>Adaptive agents in evolutionary games</h4>
<p>Adaptive agents in evolutionary games adopt behaviors in a manner similar to the way people come to have a particular accent or to speak a particular language, by repeated trial-and-error, possibly by supervised learning, more commonly by reinforcement learning.</p>
<p>Forward-looking payoff-based calculation is not entirely absent. For example those aspiring to upward mobility may adopt upper class accents. But in evolutionary theories of adaptive agent behavior, conscious optimizing is not the whole story. </p>
<blockquote>
<blockquote>
<blockquote>
<p><strong>Example</strong>: The answer to “why do you talk that way?” is generally “because this is how people talk where I come from” not “because I considered all the ways of speaking and decided that speaking this way best serves my personal goals,” although it may be for some individuals.</p>
</blockquote>
</blockquote>
</blockquote>
<h2>Dynamical Systems</h2>
<p>There are two major types of dynamical systems:</p>
<ol>
<li>a continuous time system using differential equations, and </li>
<li>a discrete time system using Markov chains</li>
</ol>
<p>An equilibrium of this dynamical system, also called a critical point or fixed point, or stationary point.  at an equilibrium, dx=dt = dy=dt = 0, so the dynamical system remains forever at (x<em>; y</em>) once it reaches there. Under what conditions does a dynamical system move toward an equilibrium?</p>
<p>Very few dynamical systems, even simple ones in two dimensions, can be solved analytically, so the paths x(t) and y(t) cannot be written in closed form. Nevertheless, there are well-developed methods for determining when an equilibrium is stable, unstable, or neutrally stable, using tools from algebra and calculus</p>
<h4>Markov Chain</h4>
<p>A finite Markov chain is a dynamical system that can be in any of n states (s<sub>1</sub>, …, s<sub>n</sub>), and if the system is in state i in time period t, it will be in state j in time period t+1 with probability p<sub>ij</sub> . Of course, for this to make sense, we must have p<sub>ij</sub> ≥ 0 for all i, j = 1, …, n, and Sum<sup>n</sup><sub>j=1</sub> (p<sub>ij</sub>) = 1. Statistical estimates of these probabilities, based on thousands of implementations of our model, for example, are the basis of our calculation of the vector field ... giving the movement of the population among the states indicating various frequencies of altruists and of parochials.</p>
<p>When a Markov chain has the property that the average fraction of time in each state in the long run is independent from the starting state, we say the system is ergodic, and we call the resulting long-run distribution of probabilities the stationary distribution of the Markov chain.</p>
<h4>The Replicator Dynamic</h4>
<p>The most natural dynamic to apply to an evolutionary game is the <strong>replicator dynamic</strong></p>
<p>it can be shown that <em>every equilibrium of an evolutionary game under the replicator dynamic is a Nash equilibrium of the stage game</em>. This shows that the Nash equilibrium criterion remains powerful even without assuming that players are rational (i.e., that they choose best responses) or coordinated.</p>
<p>Maynard Smith developed the stronger notion of an <strong>evolutionarily stable strategy</strong>: i.e., a whole population using that strategy cannot be invaded by a small group playing any other strategy. </p>
<hr>
<p><strong> Part 0 : </strong> 
<a href="https://pluteski.github.io/speech-to-text/key-lessons-from-a-cooperative-species-part-0.md.html">Overview of 14 key lessons of cooperative economics</a>.</p>
<p><strong> Part 1 : </strong> 
<a href="https://pluteski.github.io/speech-to-text/key-lessons-from-a-cooperative-species-part-2.md.html">Overview of competing alternatives</a>.</p>
<p><strong> Part 2 : </strong> 
<a href="https://pluteski.github.io/speech-to-text/key-lessons-from-a-cooperative-species-part-2.md.html">Failures of non-cooperative theory</a>.</p>
<p><strong> Part 3 : </strong> 
<a href="https://pluteski.github.io/speech-to-text/key-lessons-from-a-cooperative-species-part-3.md.html">Evolutionary economics, rise of institutions, and the co-evolution of genes and culture</a>.</p>
<hr>
<p>≠ 
≥
≤</p>
</article>

        <footer>
            <nav>
                <ul>
                </ul>
            </nav>
                <p id="theme-credit"><a href="http://mathieu.agopian.info/mnmlist/theme.html">Thème mnmlist</a></p>
        </footer>

    <script type="text/javascript">
    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
    document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
    </script>
    <script type="text/javascript">
    try {
        var pageTracker = _gat._getTracker("UA-123156804-1");
    pageTracker._trackPageview();
    } catch(err) {}</script>
<script type="text/javascript">
    var disqus_shortname = 'pluteski-github-io-speech-to-text';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</body>
</html>